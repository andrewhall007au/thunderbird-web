---
phase: 09-monitoring-alerting
plan: 05
type: execute
wave: 3
depends_on: ["09-01", "09-02", "09-03", "09-04"]
files_modified:
  - backend/monitoring/self_monitor.py
  - backend/monitoring/reporting.py
  - backend/monitoring/scheduler.py
  - backend/monitoring/deploy/monitoring.service
  - backend/monitoring/deploy/setup_monitoring.sh
  - backend/monitoring/requirements.txt
autonomous: false

must_haves:
  truths:
    - "Monitoring service monitors itself - alerts if no checks run for 10 minutes"
    - "Daily summary email is sent at 8 AM with previous day's health stats"
    - "Weekly report is sent every Monday at 8 AM with past week's health stats"
    - "Monthly report is sent on the 1st of each month with past month's health stats"
    - "Old metrics are cleaned up automatically (90-day retention)"
    - "Monitoring service runs as a systemd service on production"
    - "Monitoring service restarts automatically if it crashes"
  artifacts:
    - path: "backend/monitoring/self_monitor.py"
      provides: "Self-monitoring / heartbeat for the monitoring service"
      exports: ["check_self_health", "send_heartbeat"]
      contains: "heartbeat"
    - path: "backend/monitoring/reporting.py"
      provides: "Daily, weekly, and monthly report generation and email delivery"
      exports: ["generate_daily_summary", "generate_weekly_report", "generate_monthly_report", "send_daily_report", "send_weekly_report", "send_monthly_report"]
      contains: "weekly"
    - path: "backend/monitoring/deploy/monitoring.service"
      provides: "Systemd service file for production deployment"
      contains: "systemd"
    - path: "backend/monitoring/deploy/setup_monitoring.sh"
      provides: "Deployment script for setting up monitoring on production server"
      contains: "systemctl"
    - path: "backend/monitoring/requirements.txt"
      provides: "Python dependencies for monitoring service"
      contains: "apscheduler"
  key_links:
    - from: "backend/monitoring/self_monitor.py"
      to: "backend/monitoring/storage.py"
      via: "checks last metric timestamp to detect stale monitoring"
      pattern: "get_recent_metrics|timestamp"
    - from: "backend/monitoring/reporting.py"
      to: "backend/monitoring/storage.py"
      via: "queries metrics for daily/weekly/monthly summaries"
      pattern: "get_uptime_stats"
---

<objective>
Add self-monitoring, automated reporting (daily, weekly, monthly), metrics cleanup, and production deployment configuration.

Purpose: Complete the monitoring system with operational necessities: the monitor must monitor itself (MON-10), generate health reports at daily/weekly/monthly cadences (MON-08), clean up old data, and be deployable to production as a long-running service.

Output: Self-monitoring heartbeat, daily/weekly/monthly report generation, systemd service file, and deployment script for production setup.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/09-monitoring-alerting/09-RESEARCH.md
@.planning/phases/09-monitoring-alerting/09-01-SUMMARY.md
@.planning/phases/09-monitoring-alerting/09-02-SUMMARY.md

# Production deployment patterns
@backend/deploy/nginx_complete.conf
</context>

<tasks>

<task type="auto">
  <name>Task 1: Self-monitoring, daily/weekly/monthly reporting, and requirements</name>
  <files>
    backend/monitoring/self_monitor.py
    backend/monitoring/reporting.py
    backend/monitoring/scheduler.py
    backend/monitoring/requirements.txt
  </files>
  <action>
**backend/monitoring/self_monitor.py** - Self-monitoring (MON-10):

`check_self_health() -> dict`:
- Query storage for the most recent metric across all checks
- If no metrics exist or latest metric is older than 10 minutes: return `{"healthy": False, "reason": "No recent checks"}`
- Check scheduler is running (passed as dependency or global): return status
- Check database file exists and is writable
- Return `{"healthy": True, "last_check_age_seconds": N, "db_size_mb": N, "scheduler_running": True}`

`send_heartbeat(config, storage)`:
- Called by scheduler every 5 minutes
- Stores a self-check metric: `store_metric("self_heartbeat", "pass", 0)`
- If self-health check fails:
  - Send SMS alert (using channels directly, bypassing dedup since this is meta-monitoring)
  - Message: "THUNDERBIRD MONITOR: Monitoring service unhealthy - {reason}"

**Stale monitoring detection:**
Add a secondary check mechanism. The monitoring service's own `/health` endpoint (from Plan 01) can be monitored by an external free service:
- Document in comments: "Register this URL with https://healthchecks.io (free tier) or UptimeRobot to get external meta-monitoring"
- The `/health` endpoint should return unhealthy if last check age > 10 minutes

**backend/monitoring/reporting.py** - Daily, weekly, and monthly reports (MON-08):

`generate_daily_summary(storage, date=None) -> dict`:
- Default to yesterday's date
- Query metrics for the 24-hour period
- Calculate per-check stats: uptime %, total checks, failures, avg duration
- Calculate overall stats: total checks run, total failures, overall uptime
- Count incidents that occurred during the period
- Return structured dict with all stats

`generate_weekly_report(storage, week_ending=None) -> dict`:
- Default to the past 7 days ending yesterday
- Query metrics for the 7-day period
- Calculate per-check stats: uptime %, total checks, failures, avg duration, worst day
- Calculate overall stats: total checks run, total failures, overall uptime
- List all incidents during the week with severity, duration, resolution status
- Compare to previous week (uptime trend: improving, stable, degrading)
- Return structured dict with all stats and trends

`generate_monthly_report(storage, month=None) -> dict`:
- Default to the previous calendar month
- Query metrics for the full month
- Calculate per-check stats: uptime %, total checks, failures, avg duration
- Calculate overall stats: total checks run, total failures, overall uptime
- SLA compliance: track if uptime met 99.9% target
- Incident post-mortem summaries: list all incidents with severity, duration, root cause (from incident message), and resolution
- Compare to previous month (uptime trend)
- Return structured dict with all stats, SLA status, and incident summaries

`format_daily_report_html(summary: dict) -> str`:
- Generate HTML email with:
  - Header: "Thunderbird Daily Health Report - {date}"
  - Overall status badge (green if >99.9% uptime, yellow if >99%, red otherwise)
  - Table of checks: name, uptime %, checks run, failures, avg response time
  - Incidents section: list any incidents with severity, duration, status
  - Footer: link to /monitoring dashboard
- Use inline CSS (email-safe styling)

`format_weekly_report_html(report: dict) -> str`:
- Generate HTML email with:
  - Header: "Thunderbird Weekly Health Report - Week of {start_date}"
  - Overall status badge with week-over-week trend arrow
  - Table of checks with weekly uptime % and trend vs previous week
  - Worst performing check highlighted
  - All incidents during the week in a summary table
  - Footer: link to /monitoring dashboard

`format_monthly_report_html(report: dict) -> str`:
- Generate HTML email with:
  - Header: "Thunderbird Monthly Health Report - {month_name} {year}"
  - SLA compliance badge: green "SLA Met (99.95%)" or red "SLA Missed (98.7%)"
  - Table of checks with monthly uptime % and trend vs previous month
  - Incident post-mortems section: each incident with severity, duration, message, resolution
  - Month-over-month comparison
  - Footer: link to /monitoring dashboard

`send_daily_report(config, storage)`:
- Generate summary for yesterday
- Format as HTML
- Send via Resend to configured ALERT_EMAIL_ADDRESSES
- Subject: "[Thunderbird] Daily Health Report - {date} - {uptime}% uptime"
- Log success/failure

`send_weekly_report(config, storage)`:
- Generate weekly report
- Format as HTML
- Send via Resend to configured ALERT_EMAIL_ADDRESSES
- Subject: "[Thunderbird] Weekly Health Report - Week of {start_date} - {uptime}% uptime"
- Log success/failure

`send_monthly_report(config, storage)`:
- Generate monthly report
- Format as HTML
- Send via Resend to configured ALERT_EMAIL_ADDRESSES
- Subject: "[Thunderbird] Monthly Health Report - {month_name} {year} - {uptime}% uptime - SLA {met/missed}"
- Log success/failure

**Update backend/monitoring/scheduler.py**:
- Add self-monitoring heartbeat job: every 5 minutes, calls `send_heartbeat()`
- Add daily report job: cron trigger at 8:00 AM UTC, calls `send_daily_report()`
- Add weekly report job: cron trigger at Monday 8:00 AM UTC, calls `send_weekly_report()`
- Add monthly report job: cron trigger at 1st of month 8:00 AM UTC, calls `send_monthly_report()`
- Add cleanup job: cron trigger at 3:00 AM UTC, calls `cleanup_old_metrics(retention_days=90)` (if not already added in Plan 01)
- Ensure all new jobs have proper error handling (job failures logged, never crash scheduler)

**backend/monitoring/requirements.txt**:
```
fastapi>=0.109.0
uvicorn>=0.27.0
apscheduler>=3.10.4
requests>=2.31.0
twilio>=8.0.0
resend>=0.7.0
pydantic-settings>=2.0.0
```
Note: Playwright is NOT in requirements.txt - it's a Node.js dependency managed via npm/npx. The synthetic runner calls it via subprocess.
  </action>
  <verify>
1. `python -c "from monitoring.self_monitor import check_self_health, send_heartbeat; print('Self-monitor OK')"` from backend/
2. `python -c "from monitoring.reporting import generate_daily_summary, generate_weekly_report, generate_monthly_report, send_daily_report, send_weekly_report, send_monthly_report; print('Reporting OK')"` from backend/
3. `cat backend/monitoring/requirements.txt` shows all dependencies
4. `grep -c 'add_job' backend/monitoring/scheduler.py` shows total job count (should be 10+: health, beta, weather, db_query, external_api, synthetic_beta, synthetic_checkout, synthetic_create, synthetic_login, synthetic_sms_webhook, heartbeat, daily_report, weekly_report, monthly_report, cleanup)
  </verify>
  <done>Self-monitoring heartbeat runs every 5 minutes and alerts if monitoring itself is unhealthy. Daily health report emails at 8 AM UTC. Weekly report emails every Monday at 8 AM UTC with trends. Monthly report emails on 1st of month at 8 AM UTC with SLA compliance and post-mortems. Metrics cleanup runs nightly with 90-day retention. All dependencies documented in requirements.txt.</done>
</task>

<task type="auto">
  <name>Task 2: Production deployment configuration</name>
  <files>
    backend/monitoring/deploy/monitoring.service
    backend/monitoring/deploy/setup_monitoring.sh
  </files>
  <action>
**backend/monitoring/deploy/monitoring.service** - Systemd service file:

```ini
[Unit]
Description=Thunderbird Monitoring Service
After=network.target
Wants=network.target

[Service]
Type=simple
User=root
WorkingDirectory=/root/overland-weather/backend
Environment=PYTHONPATH=/root/overland-weather/backend
ExecStart=/root/overland-weather/venv/bin/python -m monitoring.main
Restart=always
RestartSec=10
StandardOutput=append:/var/log/thunderbird-monitoring.log
StandardError=append:/var/log/thunderbird-monitoring.log

# Environment variables (override via /etc/default/thunderbird-monitoring)
EnvironmentFile=-/etc/default/thunderbird-monitoring

[Install]
WantedBy=multi-user.target
```

Note: The production server uses `/root/overland-weather/` as the project directory and `venv/` for the Python virtualenv (same pattern as the existing deployment).

**backend/monitoring/deploy/setup_monitoring.sh** - Deployment script:

```bash
#!/bin/bash
# Setup Thunderbird Monitoring Service on production
# Run as root on the production server

set -e

echo "=== Thunderbird Monitoring Setup ==="

PROJECT_DIR="/root/overland-weather"
VENV_DIR="$PROJECT_DIR/venv"

# 1. Install Python dependencies
echo "Installing monitoring dependencies..."
$VENV_DIR/bin/pip install -r $PROJECT_DIR/backend/monitoring/requirements.txt

# 2. Install Playwright (for synthetic checks)
echo "Installing Playwright..."
cd $PROJECT_DIR
npx playwright install chromium --with-deps

# 3. Create environment file
echo "Creating environment config..."
if [ ! -f /etc/default/thunderbird-monitoring ]; then
    cat > /etc/default/thunderbird-monitoring << 'ENVEOF'
# Thunderbird Monitoring Configuration
# Edit phone numbers and email addresses for alerts

MONITOR_PRODUCTION_URL=https://thunderbird.bot
MONITOR_ALERT_PHONE_NUMBERS=+61XXXXXXXXX
MONITOR_ALERT_EMAIL_ADDRESSES=admin@thunderbird.bot

# These should match the main app's .env
# TWILIO_ACCOUNT_SID=xxx
# TWILIO_AUTH_TOKEN=xxx
# TWILIO_PHONE_NUMBER=xxx
# RESEND_API_KEY=xxx
ENVEOF
    echo "Created /etc/default/thunderbird-monitoring - EDIT THIS FILE with real values"
fi

# 4. Initialize monitoring database
echo "Initializing monitoring database..."
cd $PROJECT_DIR/backend
$VENV_DIR/bin/python -c "from monitoring.storage import init_db; init_db(); print('Database initialized')"

# 5. Install and enable systemd service
echo "Installing systemd service..."
cp $PROJECT_DIR/backend/monitoring/deploy/monitoring.service /etc/systemd/system/thunderbird-monitoring.service
systemctl daemon-reload
systemctl enable thunderbird-monitoring
systemctl start thunderbird-monitoring

# 6. Verify service is running
sleep 3
if systemctl is-active --quiet thunderbird-monitoring; then
    echo "Monitoring service started successfully!"
    echo "Check status: systemctl status thunderbird-monitoring"
    echo "View logs: journalctl -u thunderbird-monitoring -f"
    echo "Dashboard: https://thunderbird.bot/monitoring"
else
    echo "ERROR: Monitoring service failed to start"
    echo "Check logs: journalctl -u thunderbird-monitoring -n 50"
    exit 1
fi

# 7. Disable old cron-based quick_monitor if it exists
if crontab -l 2>/dev/null | grep -q "quick_monitor"; then
    echo "Note: Old quick_monitor cron job detected. Consider removing it:"
    echo "  crontab -e  # Remove the quick_monitor line"
fi

echo ""
echo "=== Setup Complete ==="
echo "Next steps:"
echo "  1. Edit /etc/default/thunderbird-monitoring with real phone/email"
echo "  2. Verify: curl http://localhost:8001/health"
echo "  3. Optional: Register http://thunderbird.bot:8001/health with healthchecks.io"
```

Make the script executable in its permissions comment.
  </action>
  <verify>
1. `ls -la backend/monitoring/deploy/` shows both files exist
2. `cat backend/monitoring/deploy/monitoring.service` shows valid systemd unit structure
3. `bash -n backend/monitoring/deploy/setup_monitoring.sh` validates script syntax
  </verify>
  <done>Systemd service file configured for auto-restart monitoring service. Deployment script installs dependencies, Playwright, creates config template, initializes DB, installs and starts the service. Old cron-based quick_monitor detection included.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Complete monitoring system: health checks (including DB query performance and external API latency), synthetic tests (including login and SMS webhook), alert manager with SMS/email and acknowledgment, status dashboard with timeline, self-monitoring, daily/weekly/monthly reports, and production deployment config.</what-built>
  <how-to-verify>
1. Start monitoring service locally: `cd backend && python -m monitoring.main`
2. Verify health endpoint: `curl http://localhost:8001/health` returns healthy
3. Verify metrics API: `curl http://localhost:8001/api/monitoring/status` returns check statuses
4. Start Next.js dev server: `npm run dev` and visit http://localhost:3000/monitoring
5. Verify dashboard shows status cards, uptime bars, and incident log
6. Verify incident acknowledge button is present on active incidents
7. Verify incident timeline expands showing event progression
8. Check scheduler is running jobs: monitoring service logs should show check executions
9. Review deployment files: `cat backend/monitoring/deploy/monitoring.service`
  </how-to-verify>
  <resume-signal>Type "approved" to proceed with production deployment, or describe issues to fix.</resume-signal>
</task>

</tasks>

<verification>
- Self-monitoring heartbeat detects if monitoring itself stops
- Daily report generates correct summary and sends via email
- Weekly report generates with trends and sends every Monday
- Monthly report generates with SLA compliance and incident post-mortems
- Metrics cleanup removes data older than 90 days
- Systemd service file is valid and configured for auto-restart
- Deployment script handles full setup from scratch
- Requirements.txt includes all Python dependencies
- Monitoring service runs independently from main backend
</verification>

<success_criteria>
- Monitoring service can be deployed to production with a single script
- Service auto-restarts on crash (systemd Restart=always)
- Self-monitoring alerts if no checks run for 10 minutes
- Daily summary email arrives at 8 AM with previous day's stats
- Weekly report arrives every Monday at 8 AM with week's stats and trends
- Monthly report arrives on the 1st at 8 AM with SLA compliance and post-mortems
- Old metrics cleaned up nightly (90-day retention)
- Old cron-based quick_monitor can be decommissioned
</success_criteria>

<output>
After completion, create `.planning/phases/09-monitoring-alerting/09-05-SUMMARY.md`
</output>
