---
phase: 09-monitoring-alerting
plan: 03
type: execute
wave: 2
depends_on: ["09-01"]
files_modified:
  - backend/monitoring/checks_synthetic.py
  - backend/monitoring/scheduler.py
  - e2e/monitoring.config.ts
autonomous: true

must_haves:
  truths:
    - "Existing Playwright E2E tests run against production URL on schedule"
    - "Beta signup flow is tested every 5 minutes via Playwright"
    - "Synthetic test results are stored as metrics with pass/fail and duration"
    - "Playwright test failures include error details for debugging"
  artifacts:
    - path: "backend/monitoring/checks_synthetic.py"
      provides: "Playwright test runner for synthetic monitoring"
      exports: ["run_playwright_check"]
      contains: "subprocess"
    - path: "e2e/monitoring.config.ts"
      provides: "Playwright config for monitoring (production URL, generous timeouts)"
      contains: "thunderbird.bot"
  key_links:
    - from: "backend/monitoring/checks_synthetic.py"
      to: "e2e/*.spec.ts"
      via: "subprocess runs Playwright tests"
      pattern: "npx.*playwright.*test"
    - from: "backend/monitoring/scheduler.py"
      to: "backend/monitoring/checks_synthetic.py"
      via: "scheduler calls synthetic checks on interval"
      pattern: "run_playwright_check"
---

<objective>
Wire existing Playwright E2E tests as synthetic monitors running against production on schedule.

Purpose: HTTP health checks (Plan 01) catch server-level issues but miss UI/JavaScript bugs like the BetaApplyModal production bug. Playwright synthetic tests catch real user-facing issues by exercising actual browser flows.

Output: Synthetic test runner that executes existing E2E tests against production, stores results as metrics, and integrates with the scheduler.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/09-monitoring-alerting/09-RESEARCH.md
@.planning/phases/09-monitoring-alerting/09-01-SUMMARY.md

# Existing E2E tests to reuse
@e2e/beta-signup-flow.spec.ts
@e2e/buy-now-flow.spec.ts
@e2e/create-first-flow.spec.ts
@e2e/fixtures.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Playwright monitoring config and synthetic test runner</name>
  <files>
    e2e/monitoring.config.ts
    backend/monitoring/checks_synthetic.py
  </files>
  <action>
**e2e/monitoring.config.ts** - Playwright config for monitoring runs:

Create a separate Playwright config specifically for monitoring (don't modify the existing playwright.config.ts used for development/CI). This config:
- `baseURL`: `process.env.MONITOR_BASE_URL || 'https://thunderbird.bot'` (always targets production)
- `timeout`: 120_000 (120 seconds - generous for production, per research guidance)
- `retries`: 0 (monitoring should report actual state, not retry away failures)
- `workers`: 1 (single worker to avoid parallel browser load)
- `reporter`: [['json', { outputFile: '/tmp/playwright-monitor-results.json' }]]
- `use.headless`: true
- `use.actionTimeout`: 30_000
- Projects: single project with chromium only (lightweight)

**backend/monitoring/checks_synthetic.py** - Synthetic test runner:

`run_playwright_check(test_file: str, test_name: str | None = None) -> CheckResult`:
- Runs a Playwright test against production using subprocess
- Command: `npx playwright test {test_file} --config=e2e/monitoring.config.ts --reporter=json`
- If `test_name` provided, add `--grep "{test_name}"` to run specific test
- Set environment variables:
  - `BASE_URL=https://thunderbird.bot` (or from config)
  - `NODE_ENV=production`
  - `CI=true` (suppresses interactive prompts)
- Set working directory to project root (parent of backend/)
- Timeout: 180 seconds (subprocess timeout)
- Parse JSON output from stdout to extract:
  - Overall pass/fail status
  - Duration in milliseconds
  - Error message if failed (extract from `suites[0].specs[0].tests[0].results[0].error.message`)
- Return `CheckResult` with:
  - `check_name`: derived from test_file (e.g., "beta-signup-flow.spec.ts" -> "synthetic_beta_signup")
  - `status`: 'pass' or 'fail'
  - `duration_ms`: total test duration
  - `error_message`: extracted error or timeout message
  - `metadata`: {"test_file": test_file, "output_file": "/tmp/playwright-monitor-results.json"}

Handle edge cases:
- `subprocess.TimeoutExpired`: Return fail with "Test timed out after 180 seconds"
- `FileNotFoundError` (npx not found): Return fail with "Playwright not installed"
- JSON parse failure: Return fail with raw stderr output (first 500 chars)
- Any other exception: Return fail with exception message

Convenience functions for scheduled use:
- `check_beta_signup_synthetic() -> CheckResult`: Runs `beta-signup-flow.spec.ts`
- `check_buy_now_synthetic() -> CheckResult`: Runs `buy-now-flow.spec.ts`
- `check_create_first_synthetic() -> CheckResult`: Runs `create-first-flow.spec.ts`

IMPORTANT: These synthetic checks should NOT create real data in production. The existing E2E tests may need to be examined - if they create real beta signups or purchases, the monitoring check should note this in its docstring. The test_file names map to existing files in e2e/ directory. If a test creates side effects, document it but still run it (the data cleanup is a future concern, the monitoring value outweighs the small data pollution).
  </action>
  <verify>
1. `python -c "from monitoring.checks_synthetic import run_playwright_check, check_beta_signup_synthetic; print('Synthetic imports OK')"` from backend/ directory.
2. Verify monitoring.config.ts is valid: `npx playwright test --config=e2e/monitoring.config.ts --list` from project root (may show tests or config error - just verify it parses).
  </verify>
  <done>Playwright synthetic test runner wraps existing E2E tests, runs them against production URL with generous timeouts, parses JSON results into CheckResult format, handles all error cases gracefully.</done>
</task>

<task type="auto">
  <name>Task 2: Wire synthetic checks into scheduler</name>
  <files>
    backend/monitoring/scheduler.py
  </files>
  <action>
Update `backend/monitoring/scheduler.py` to add synthetic check jobs:

Add these scheduled jobs to `create_scheduler()`:

1. `synthetic_beta_signup` (every 5 minutes):
   - Calls `check_beta_signup_synthetic()`
   - This is the MOST critical synthetic check (catches bugs like the BetaApplyModal issue)
   - Classified as severity=critical in alert manager

2. `synthetic_checkout` (every 15 minutes):
   - Calls `check_buy_now_synthetic()`
   - Revenue-critical flow
   - Classified as severity=critical

3. `synthetic_create_first` (every 15 minutes):
   - Calls `check_create_first_synthetic()`
   - User experience flow
   - Classified as severity=warning

Each synthetic job:
- Wraps the check call in try/except (synthetic failures should never crash scheduler)
- Calls `alert_manager.evaluate_and_alert(result)` after each check (if alert_manager is wired in from Plan 02; if Plan 02 not yet executed, just call `store_metric()` directly)
- Logs start and completion of each synthetic check with timing

Make the synthetic checks conditional: only add them if Playwright is available on the system (check for `npx` in PATH). If not available, log a warning and skip synthetic jobs. This allows the monitoring service to run in environments without Node.js installed (e.g., development) while still providing HTTP-based checks.

```python
import shutil
PLAYWRIGHT_AVAILABLE = shutil.which('npx') is not None

if PLAYWRIGHT_AVAILABLE:
    # Add synthetic check jobs
    ...
else:
    logger.warning("npx not found - synthetic Playwright checks disabled")
```
  </action>
  <verify>
1. `python -c "from monitoring.scheduler import create_scheduler; s = create_scheduler(); jobs = s.get_jobs(); print(f'{len(jobs)} jobs configured'); [print(f'  {j.id}: {j.trigger}') for j in jobs]"` from backend/ directory shows synthetic jobs listed.
2. Verify conditional behavior: synthetic jobs appear only if npx is available.
  </verify>
  <done>Scheduler runs synthetic Playwright tests at configured intervals (beta signup every 5min, checkout every 15min, create-first every 15min). Synthetic checks are conditionally enabled based on Playwright availability. Results flow through the same metric storage and alert pipeline as HTTP checks.</done>
</task>

</tasks>

<verification>
- Playwright monitoring config exists with production URL and generous timeouts
- Synthetic test runner successfully executes existing E2E tests via subprocess
- Results parsed from Playwright JSON output into CheckResult format
- Scheduler includes synthetic check jobs at correct intervals
- Synthetic checks gracefully handle Playwright not being installed
- Error cases (timeout, parse failure, missing dependency) all return structured CheckResult
</verification>

<success_criteria>
- Beta signup synthetic test catches the same BetaApplyModal bug that was caught manually
- Synthetic tests run every 5-15 minutes against production
- Test failures include actionable error details (which test, what assertion failed)
- Monitoring service still works if Playwright is not installed (HTTP checks only)
- No test data pollution awareness documented (even if tests create data)
</success_criteria>

<output>
After completion, create `.planning/phases/09-monitoring-alerting/09-03-SUMMARY.md`
</output>
