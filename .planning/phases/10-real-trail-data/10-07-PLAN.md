---
phase: 10-real-trail-data
plan: 07
type: execute
wave: 4
depends_on: ["10-06"]
files_modified:
  - scripts/trail-curation/distance-report.ts
autonomous: false

must_haves:
  truths:
    - "Distance validation report generated for all 350+ trails"
    - "No trail is >2% shorter than its official distance without being flagged and reviewed"
    - "User has visually spot-checked trail overlay accuracy for flagged trails"
    - "Data source attribution is present (OSM, government sources, manual)"
    - "Flagged trails at this stage are post-fallback genuine hard cases only"
  artifacts:
    - path: "scripts/trail-curation/distance-report.ts"
      provides: "Generates distance validation report for all trails in popularTrails.ts, including data source breakdown"
  key_links:
    - from: "scripts/trail-curation/distance-report.ts"
      to: "app/data/popularTrails.ts"
      via: "import popularTrails"
      pattern: "import.*popularTrails"
---

<objective>
Run final accuracy validation on all trail data, generate distance report with data source attribution, and get user sign-off on trail quality via visual spot-checking.

Purpose: This is the quality gate ensuring we don't ship inaccurate trail data. By this point, the automated fallback pipeline (Plan 01) has already retried failed trails through OSM + country-specific government sources (USFS, Parks Canada, DOC, Natural England, IGN, SwissTopo, etc.). Any trails still flagged here are genuine hard cases that exhausted ALL automated sources. The number of remaining flagged trails should be significantly smaller than 10% thanks to the fallback chain.

Output: Validation report with source attribution breakdown and user approval of trail data quality.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Integration complete
@.planning/phases/10-real-trail-data/10-06-SUMMARY.md

# Current trail data
@app/data/popularTrails.ts (first 15 lines)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create and run distance validation report with source attribution across all trails</name>
  <files>
    scripts/trail-curation/distance-report.ts
  </files>
  <action>
1. Create `scripts/trail-curation/distance-report.ts`:
   - Import popularTrails from the app data file (use relative path to `../../app/data/popularTrails`)
   - For each trail, calculate total haversine distance from its coordinates
   - Compare against distance_km field (which is the official distance)
   - Flag any trail where calculated distance is >2% shorter than official OR >20% longer (likely bad data)
   - Generate a markdown report with TWO sections:

   **Section 1: Data Source Attribution Summary**
   ```
   ## Data Source Attribution

   | Source | Trail Count | Percentage |
   |--------|------------|------------|
   | OpenStreetMap | 280 | 80% |
   | USFS National Forest Trails | 8 | 2.3% |
   | DOC Tracks (NZ) | 12 | 3.4% |
   | Parks Canada | 5 | 1.4% |
   | Tasmania ListMap | 6 | 1.7% |
   | Natural England | 3 | 0.9% |
   | ... | ... | ... |
   | Manual trace | 5 | 1.4% |
   | **Total** | **350** | **100%** |
   ```
   This data comes from the `dataSource` field on each trail (populated during fetch). If the trail data doesn't include a dataSource field (e.g., for manually entered trails), default to "manual".

   **Section 2: Distance Validation Table**
   ```
   | Country | Trail | Official (km) | Calculated (km) | Diff (%) | Source | Status |
   ```
   - Status: PASS (within 2%), FLAG (>2% short), WARN (>20% long), SKIP (no official distance)
   - Source column shows which data source provided the coordinates (e.g., "OSM", "USFS", "DOC", "manual")

   Write report to `scripts/trail-curation/VALIDATION-REPORT.md`
   Print summary:
   ```
   === VALIDATION SUMMARY ===
   Total trails: 350
   Passed: 330 (94%)
   Flagged (>2% short): 12 (3.4%)
   Warned (>20% long): 3 (0.9%)
   Skipped (no distance): 5 (1.4%)

   === SOURCE BREAKDOWN OF FLAGGED TRAILS ===
   From OSM: 5 flagged
   From government sources: 4 flagged
   From manual trace: 3 flagged
   ```

2. Run the validation:
   ```
   npx tsx scripts/trail-curation/distance-report.ts
   ```

3. Review flagged trails. IMPORTANT: By this stage, flagged trails have already been through the full fallback pipeline. They are genuine hard cases. For each:
   - If the trail was sourced from a government dataset and still fails distance validation, the issue is likely: (a) the government data covers a different section than the "official" distance, or (b) the official distance is for a different route variant. Adjust the officialDistanceKm if warranted.
   - For trails flagged as "too short": check if simplification was too aggressive -- re-fetch with higher target points (150-200).
   - For trails flagged as "too long": check if the data includes side trails or alternate routes.
   - For manual-trace trails: these are approximate by nature -- consider widening the tolerance to 5% for manual entries.

4. Re-run validation after fixes. Target: fewer than 5% flagged (stricter than previous 10% target, because the fallback chain should have already fixed most issues at the data source level).

5. Ensure data source attribution: Add a comment at the top of popularTrails.ts:
   ```
   // Trail coordinate data sourced from:
   // - OpenStreetMap (openstreetmap.org) - Data (c) OpenStreetMap contributors, licensed under ODbL
   // - USDA Forest Service (fs.usda.gov) - Public domain
   // - National Park Service (nps.gov) - Public domain
   // - Department of Conservation NZ (doc.govt.nz) - CC BY 4.0
   // - Parks Canada (parks.canada.ca) - Open Government Licence
   // - Tasmania Parks and Wildlife (parks.tas.gov.au) - CC BY 4.0
   // - Natural England (naturalengland.org.uk) - Open Government Licence
   // - IGN France (ign.fr) - Licence Ouverte
   // - SwissTopo (swisstopo.admin.ch) - Open use
   // - Other government open data sources (see VALIDATION-REPORT.md for per-trail attribution)
   // Coordinates simplified for use as visual planning aids only
   ```
  </action>
  <verify>
VALIDATION-REPORT.md exists with entries for all 350+ trails. Includes data source attribution summary table. Fewer than 5% flagged (post-fallback). Attribution comment in popularTrails.ts includes all data sources used.
  </verify>
  <done>
Distance validation complete for all trails with source attribution. Fewer than 5% flagged (these are post-fallback genuine hard cases, documented with reasons). Multi-source attribution added covering OSM and all government sources used.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Complete trail data replacement: 350+ trails with real coordinate data from OSM and government open data sources, grouped by country in the UI, with distance validation report and source attribution.
  </what-built>
  <how-to-verify>
1. Run `npm run dev` and navigate to the route builder page
2. Open the trail selector -- verify trails are grouped by country with headers
3. Verify all 11 weather API countries appear (AU, CA, FR, DE, IT, JP, NZ, ZA, CH, GB, US)
4. Count approximate trails per major country: US should have ~100, AU ~50, CA ~50, NZ ~50
5. Select a few trails you know well and verify the route looks correct on the map:
   - Pacific Crest Trail (should run CA->OR->WA along the mountain spine)
   - Tour du Mont Blanc (should loop around Mont Blanc through FR/IT/CH)
   - Overland Track Tasmania (should run through Cradle Mountain region)
   - West Highland Way (should run from Glasgow area to Fort William)
   - Milford Track (should run through Fiordland)
6. Search for "Tasmania" -- should show ~25 Tasmanian trails
7. Search for "Alps" -- should show trails across multiple countries
8. Review the validation report at `scripts/trail-curation/VALIDATION-REPORT.md`:
   - Check the source attribution summary -- does the breakdown look reasonable?
   - Any flagged trails that concern you? (These are post-fallback hard cases)
   - Are the flagged trail counts lower than the previous 10% threshold?
9. Check that the overall user experience is smooth -- no lag loading 350+ trails, search is responsive
  </how-to-verify>
  <resume-signal>Type "approved" to complete Phase 10, or describe any trails that need fixing</resume-signal>
</task>

</tasks>

<verification>
1. VALIDATION-REPORT.md shows <5% flagged trails (post-fallback)
2. VALIDATION-REPORT.md includes data source attribution summary
3. User approves trail data quality after visual inspection
4. `npm run build` passes
5. All 11 countries visible in TrailSelector
6. Search works across the full 350+ trail library
</verification>

<success_criteria>
- Distance validation report generated with <5% flagged trails (post-fallback hard cases only)
- Data source attribution summary shows breakdown of OSM vs government sources
- User visually spot-checked key trails and approved accuracy
- Multi-source attribution present in popularTrails.ts (OSM, USFS, DOC, Parks Canada, etc.)
- Full build passes
- TrailSelector performance acceptable with 350+ trails
</success_criteria>

<output>
After completion, create `.planning/phases/10-real-trail-data/10-07-SUMMARY.md`
</output>
